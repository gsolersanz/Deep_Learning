{"cells":[{"cell_type":"markdown","metadata":{"id":"bAfDXEWCj8Hx"},"source":["\n","# Aprendizaje Profundo\n","## Self-Supervised Learning Assignment\n","\n","(This assignment is an adaptation from a proposal originally designed by **Antonio Ríos**).\n","\n","The goal of this exercise is to perform a simple *Self-supervised learning* experiment. In particular, we are going to implement the method proposed in the RotNet paper that was briefly seen in the theory part, and apply it to the Fashion MNIST dataset.\n","\n","First, upload this notebook to **google colab** and select the T4 GPU environment. Then, follow the next instructions."]},{"cell_type":"markdown","metadata":{"id":"m-PzsU_fZl5o"},"source":["## First part: Supervised training\n","\n","* Load the ***Fashion MNIST*** dataset using the implemented `tf.keras` loading function."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"z7Ps_BuUZl5p","executionInfo":{"status":"ok","timestamp":1741196852238,"user_tz":-60,"elapsed":6142,"user":{"displayName":"Guillem Soler","userId":"00913242824559983185"}},"outputId":"cabc3833-7297-4955-b416-7fa632ffedb5"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n","\u001b[1m29515/29515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n","Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n","\u001b[1m26421880/26421880\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n","Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n","\u001b[1m5148/5148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1us/step\n","Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n","\u001b[1m4422102/4422102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"]}],"source":["import tensorflow as tf\n","from tensorflow.keras.datasets import fashion_mnist\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n","from tensorflow.keras.utils import to_categorical\n","\n","# Cargar el dataset Fashion MNIST\n","(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n"]},{"cell_type":"markdown","metadata":{"id":"lzvyUomIZl5q"},"source":["\n","* Make a division of the training set. The first 10.000 samples will remain as they are with their labels. Store the rest (without labels) in another set. This unlabeled set will be used later in the second part for the self-supervised experiment."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-_NQnfqiZl5q"},"outputs":[],"source":["x_labeled = x_train[:10000]\n","y_labeled = y_train[:10000]\n","x_unlabeled = x_train[10000:]\n"]},{"cell_type":"markdown","metadata":{"id":"lPLh4wY_Zl5r"},"source":["\n","* We set the random seed to a fixed value for reproducibility, and use the following CNN architecture (this is already implemented).\n","\n","* Complete the following code by compiling this model with the *Categorical Cross-Entropy* loss function, a *SGD* optimizer and a *batch_size* of 512.\n","\n","* Train the model with **ten epochs** and annotate the accuracy obtained for the test set."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ayM0AYIMZl5r","executionInfo":{"status":"ok","timestamp":1741196866669,"user_tz":-60,"elapsed":133,"user":{"displayName":"Guillem Soler","userId":"00913242824559983185"}},"outputId":"06e46111-c054-4538-c539-a4ddb3b8cb8a"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]}],"source":["tf.keras.utils.set_random_seed(1)\n","\n","model = tf.keras.models.Sequential([\n","        tf.keras.layers.Conv2D(64, 7, activation=\"relu\", padding=\"same\",\n","                            input_shape=[28, 28, 1]),\n","        tf.keras.layers.MaxPooling2D(2),\n","        tf.keras.layers.Conv2D(128, 3, activation=\"relu\", padding=\"same\"),\n","        tf.keras.layers.Conv2D(128, 3, activation=\"relu\", padding=\"same\"),\n","        tf.keras.layers.MaxPooling2D(2),\n","        tf.keras.layers.Conv2D(256, 3, activation=\"relu\", padding=\"same\"),\n","        tf.keras.layers.Conv2D(256, 3, activation=\"relu\", padding=\"same\"),\n","        tf.keras.layers.MaxPooling2D(2),\n","        tf.keras.layers.Flatten(),\n","        tf.keras.layers.Dense(128, activation=\"relu\"),\n","        tf.keras.layers.Dropout(0.5),\n","        tf.keras.layers.Dense(64, activation=\"relu\"),\n","        tf.keras.layers.Dropout(0.5),\n","        tf.keras.layers.Dense(10, activation=\"softmax\")\n","])"]},{"cell_type":"code","source":["model.compile(optimizer=tf.keras.optimizers.SGD(),\n","              loss=\"categorical_crossentropy\",\n","              metrics=[\"accuracy\"])\n","\n","y_train = tf.keras.utils.to_categorical(y_train, 10)\n","y_test = tf.keras.utils.to_categorical(y_test, 10)\n","\n","history = model.fit(x_train, y_train, epochs=10, batch_size=512, validation_data=(x_test, y_test))\n","test_loss, test_acc = model.evaluate(x_test, y_test, verbose=0)\n","print(\"Test accuracy:\", test_acc)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"brPxkWRSasCr","executionInfo":{"status":"ok","timestamp":1741203098439,"user_tz":-60,"elapsed":6183507,"user":{"displayName":"Guillem Soler","userId":"00913242824559983185"}},"outputId":"f5423dff-d34d-4cfa-e751-69449bd990ec"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m597s\u001b[0m 5s/step - accuracy: 0.2573 - loss: 2.9081 - val_accuracy: 0.7289 - val_loss: 0.8884\n","Epoch 2/10\n","\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m620s\u001b[0m 5s/step - accuracy: 0.5910 - loss: 1.2147 - val_accuracy: 0.7801 - val_loss: 0.6540\n","Epoch 3/10\n","\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m607s\u001b[0m 5s/step - accuracy: 0.6735 - loss: 0.9632 - val_accuracy: 0.7983 - val_loss: 0.5576\n","Epoch 4/10\n","\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m621s\u001b[0m 5s/step - accuracy: 0.7209 - loss: 0.8280 - val_accuracy: 0.8042 - val_loss: 0.5393\n","Epoch 5/10\n","\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m620s\u001b[0m 5s/step - accuracy: 0.7460 - loss: 0.7599 - val_accuracy: 0.8216 - val_loss: 0.4877\n","Epoch 6/10\n","\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m623s\u001b[0m 5s/step - accuracy: 0.7671 - loss: 0.6929 - val_accuracy: 0.8413 - val_loss: 0.4525\n","Epoch 7/10\n","\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m621s\u001b[0m 5s/step - accuracy: 0.7802 - loss: 0.6499 - val_accuracy: 0.8512 - val_loss: 0.4263\n","Epoch 8/10\n","\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m609s\u001b[0m 5s/step - accuracy: 0.7968 - loss: 0.6021 - val_accuracy: 0.8629 - val_loss: 0.3979\n","Epoch 9/10\n","\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m608s\u001b[0m 5s/step - accuracy: 0.8060 - loss: 0.5768 - val_accuracy: 0.8545 - val_loss: 0.4062\n","Epoch 10/10\n","\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m633s\u001b[0m 5s/step - accuracy: 0.8194 - loss: 0.5430 - val_accuracy: 0.8649 - val_loss: 0.3896\n","Test accuracy: 0.8648999929428101\n"]}]},{"cell_type":"markdown","metadata":{"id":"jjCi-l5WZl5s"},"source":["## Second part: Pretext task training\n","\n","* Implement a function to generate pseudo-labels from the unlabeled set. For this, first you must choose a random number between 0 and 3. According to the obtained random value, apply a rotation (90º, 180º, 270º, No rotation). Each sample will be assigned to its corresponding label.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YGO-4VWoZl5s"},"outputs":[],"source":["import numpy as np\n","\n","def generate_pseudo_labels(x_unlabeled):\n","    pseudo_images = []\n","    pseudo_labels = []\n","    for img in x_unlabeled:\n","        r = np.random.randint(0, 4)\n","        if r == 0:\n","            rotated_img = img\n","        elif r == 1:\n","            rotated_img = np.rot90(img, k=1)\n","        elif r == 2:\n","            rotated_img = np.rot90(img, k=2)\n","        elif r == 3:\n","            rotated_img = np.rot90(img, k=3)\n","        pseudo_images.append(rotated_img)\n","        pseudo_labels.append(r)\n","    return np.array(pseudo_images), np.array(pseudo_labels)\n"]},{"cell_type":"markdown","metadata":{"id":"MD4Z97GtZl5s"},"source":["* Reimplement the same previous convolutional architecture, but adapting the last layer to the label space of our pretext task."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"e5TclHeaZl5t"},"outputs":[],"source":["tf.keras.utils.set_random_seed(1)\n","\n","model = tf.keras.models.Sequential([\n","    tf.keras.layers.Conv2D(64, 7, activation=\"relu\", padding=\"same\", input_shape=[28, 28, 1]),\n","    tf.keras.layers.MaxPooling2D(2),\n","    tf.keras.layers.Conv2D(128, 3, activation=\"relu\", padding=\"same\"),\n","    tf.keras.layers.Conv2D(128, 3, activation=\"relu\", padding=\"same\"),\n","    tf.keras.layers.MaxPooling2D(2),\n","    tf.keras.layers.Conv2D(256, 3, activation=\"relu\", padding=\"same\"),\n","    tf.keras.layers.Conv2D(256, 3, activation=\"relu\", padding=\"same\"),\n","    tf.keras.layers.MaxPooling2D(2),\n","    tf.keras.layers.Flatten(),\n","    tf.keras.layers.Dense(128, activation=\"relu\"),\n","    tf.keras.layers.Dropout(0.5),\n","    tf.keras.layers.Dense(64, activation=\"relu\"),\n","    tf.keras.layers.Dropout(0.5),\n","    tf.keras.layers.Dense(4, activation=\"softmax\")\n","])\n"]},{"cell_type":"markdown","metadata":{"id":"HWnn1h8rZl5t"},"source":["\n","* Compile the pretext model with the same parameters than the previous one.\n","\n","* Train the pretext model on 10 epochs."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iqWjQ_dZZl5t","executionInfo":{"status":"ok","timestamp":1741207995304,"user_tz":-60,"elapsed":4896571,"user":{"displayName":"Guillem Soler","userId":"00913242824559983185"}},"outputId":"d50f0766-550f-48c5-f1c8-5a3874479f4c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m473s\u001b[0m 5s/step - accuracy: 0.3586 - loss: 2.4610\n","Epoch 2/10\n","\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m471s\u001b[0m 5s/step - accuracy: 0.6878 - loss: 0.8091\n","Epoch 3/10\n","\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m472s\u001b[0m 5s/step - accuracy: 0.8114 - loss: 0.5277\n","Epoch 4/10\n","\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m500s\u001b[0m 5s/step - accuracy: 0.8620 - loss: 0.3952\n","Epoch 5/10\n","\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m504s\u001b[0m 5s/step - accuracy: 0.8919 - loss: 0.3162\n","Epoch 6/10\n","\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m471s\u001b[0m 5s/step - accuracy: 0.9140 - loss: 0.2614\n","Epoch 7/10\n","\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m499s\u001b[0m 5s/step - accuracy: 0.9238 - loss: 0.2366\n","Epoch 8/10\n","\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m468s\u001b[0m 5s/step - accuracy: 0.9342 - loss: 0.2073\n","Epoch 9/10\n","\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m501s\u001b[0m 5s/step - accuracy: 0.9400 - loss: 0.1909\n","Epoch 10/10\n","\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m506s\u001b[0m 5s/step - accuracy: 0.9468 - loss: 0.1696\n"]}],"source":["model.compile(optimizer=tf.keras.optimizers.SGD(),\n","              loss=\"categorical_crossentropy\",\n","              metrics=[\"accuracy\"])\n","\n","x_pseudo, y_pseudo = generate_pseudo_labels(x_unlabeled)\n","y_pseudo = tf.keras.utils.to_categorical(y_pseudo, 4)\n","\n","history = model.fit(x_pseudo, y_pseudo, epochs=10, batch_size=512)\n"]},{"cell_type":"markdown","metadata":{"id":"uMaERgyDZl5t"},"source":["## Third part: Fine-tuning for the downstream task\n","\n","* Replace the last layer of the pretrained rotation model by a dense layer to classify the labeled dataset. For this, it is recommended to check the functions `pop()` and `add()` from the `keras` secuential API."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZKfUbzQwZl5u"},"outputs":[],"source":["model.pop()\n","model.add(tf.keras.layers.Dense(10, activation=\"softmax\"))"]},{"cell_type":"markdown","metadata":{"id":"rjJYesReZl5u"},"source":["* **Freeze** the weights of the *first three convolutional layers*, as in the original paper, in which best embeddings are those from the second convolutional block. You can get the name of a layer using the method _layer.name_. The layers to be freezed should be called something like _conv2d_5, conv2d_6, conv2d_7_."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ESHfaHXOZl5u"},"outputs":[],"source":["for layer in model.layers:\n","    if layer.name in [\"conv2d_5\", \"conv2d_6\", \"conv2d_7\"]:\n","        layer.trainable = False\n"]},{"cell_type":"markdown","metadata":{"id":"e-syeL5-Zl5v"},"source":["* Compile the model with the same loss and optimizer than the previous ones.\n","\n","* Train the model using the labeled training set. For this, use the same number of epochs (10) than in the supervised experiment."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eHFuz_aHZl5v","executionInfo":{"status":"ok","timestamp":1741209016734,"user_tz":-60,"elapsed":698302,"user":{"displayName":"Guillem Soler","userId":"00913242824559983185"}},"outputId":"97e496ef-6ce5-45f1-9824-539c7c5eb63a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 3s/step - accuracy: 0.1371 - loss: 2.9915\n","Epoch 2/10\n","\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 3s/step - accuracy: 0.2677 - loss: 1.9980\n","Epoch 3/10\n","\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 3s/step - accuracy: 0.3193 - loss: 1.8378\n","Epoch 4/10\n","\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 3s/step - accuracy: 0.3846 - loss: 1.6744\n","Epoch 5/10\n","\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 3s/step - accuracy: 0.4409 - loss: 1.5560\n","Epoch 6/10\n","\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 3s/step - accuracy: 0.4798 - loss: 1.4397\n","Epoch 7/10\n","\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 3s/step - accuracy: 0.5123 - loss: 1.3583\n","Epoch 8/10\n","\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 3s/step - accuracy: 0.5602 - loss: 1.2489\n","Epoch 9/10\n","\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 3s/step - accuracy: 0.5709 - loss: 1.2196\n","Epoch 10/10\n","\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 3s/step - accuracy: 0.5976 - loss: 1.1331\n"]}],"source":["y_labeled = tf.keras.utils.to_categorical(y_labeled, 10)\n","model.compile(optimizer=tf.keras.optimizers.SGD(),\n","              loss=\"categorical_crossentropy\",\n","              metrics=[\"accuracy\"])\n","history = model.fit(x_labeled, y_labeled, epochs=10, batch_size=512)\n","\n"]},{"cell_type":"markdown","metadata":{"id":"rlPODvLJZl5v"},"source":["* Compare the accuracy obtained in the test set between the supervised and the self-supervised approaches, and discuss the results."]},{"cell_type":"markdown","metadata":{"id":"ORcGZgUuZl5w"},"source":["Supervised training achieved about 86.5% test accuracy by using explicit labels, which provided clear learning signals.\n","The loss consistently decreased during training, indicating effective convergence with the labeled data.\n","In contrast, the self-supervised approach, which does not rely on direct labels, only reached about 59.8% accuracy.\n","This lower performance highlights the difficulty of learning robust features without explicit guidance.\n","Overall, the results demonstrate that supervised learning can lead to much better performance when high-quality labeled data is available."]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}